<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Konstantin Mishchenko</title>
    <link>https://konstmish.github.io/post/</link>
    <description>Recent content in Posts on Konstantin Mishchenko</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019 Konstantin Mishchenko</copyright>
    <lastBuildDate>Tue, 07 Jan 2020 00:00:00 +0300</lastBuildDate>
    
	    <atom:link href="https://konstmish.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>AISTATS 2020: 3 papers accepted, 1 rejected</title>
      <link>https://konstmish.github.io/post/20_aistats/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/20_aistats/</guid>
      <description>&lt;p&gt;Today we received the final decisions for our papers submitted to the AISTATS conference (&lt;a href=&#34;https://www.aistats.org/&#34; target=&#34;_blank&#34;&gt;https://www.aistats.org/&lt;/a&gt;). Although one work was rejected, this constitutes a good acceptance rate. Unfortunately, we also had to withdraw one of our submissions. Below is the list of papers that we will present:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Revisiting Stochastic Extragradient (K. Mishchenko, D. Kovalev, E. Shulgin, Y. Malitsky and P. Richtárik)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tighter Theory for Local SGD on Identical and Heterogeneous Data (A. Khaled, K. Mishchenko and P. Richtárik)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;DAve-QN: A Distributed Averaged Quasi-Newton Method with Local Superlinear Convergence Rate (S. Soori, K. Mishchenko, A. Mokhtari, M. Dehnavi and M. Gürbüzbalaban)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Please drop by our posters in Palermo, Italy on 3-5 June!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper got accepted to the SIAM Optimization journal</title>
      <link>https://konstmish.github.io/post/19_siam/</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_siam/</guid>
      <description>&lt;p&gt;One of the first papers that I wrote got accepted to the SIAM journal on optimization (SIOPT). The review process was quite long and included several revisions, but I&amp;rsquo;m happy I got it accepted before my graduation. This work is a result of my collaboration with J. Malick and F. Iutzeler, from whose experience I learned a lot about optimization. The title of the work is &amp;ldquo;A Distributed Flexible Delay-tolerant Proximal Gradient Algorithm&amp;rdquo;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I got NeurIPS Travel Award</title>
      <link>https://konstmish.github.io/post/19_neurips_award_travel/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_neurips_award_travel/</guid>
      <description>&lt;p&gt;In addition to my free NeurIPS registration, which I received as on of the top reviewers, I will also receive $1400 from the NeurIPS Foundation to sponsor my travel to the conference.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Invited talk at Boris Polyak&#39;s seminar</title>
      <link>https://konstmish.github.io/post/19_polyak/</link>
      <pubDate>Sun, 27 Oct 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_polyak/</guid>
      <description>&lt;p&gt;I was invited by Boris Polyak to present my work on Sinkhorn algorithm at his seminar. The talk took place on Tuesday, 22 October, at the Institute of Control Sciences. It was a great pleasure to hear that Boris liked my work for its simplicity. The slides of my talk are now attached to the corresponding publication (&lt;a href=&#34;https://konstmish.github.io/publication/19_sinkhorn/&#34; target=&#34;_blank&#34;&gt;https://konstmish.github.io/publication/19_sinkhorn/&lt;/a&gt;).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NeurIPS workshops: 5 accepted papers</title>
      <link>https://konstmish.github.io/post/19_workshops/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_workshops/</guid>
      <description>&lt;p&gt;We have submitted 5 papers to 4 different workshops hosted by NeurIPS and all of them were accepted, including one work for oral presentation. The list of papers:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Stochastic Newton and Cubic Newton Methods with Simple Local Linear-Quadratic Rates (oral, with D. Kovalev and P. Richtárik)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sinkhorn Algorithm as a Special Case of Stochastic Mirror Descent (single-author work)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Better Communication Complexity for Local SGD (with A. Khaled and P. Richtárik)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;First Analysis of Local GD on Heterogeneous Data (with A. Khaled and P. Richtárik)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Revisiting Stochastic Extragradient (with D. Kovalev and P. Richtárik)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted as spotlight to NeurIPS workshop &#39;Beyond First-Order Methods in ML&#39;</title>
      <link>https://konstmish.github.io/post/19_neurips_newton/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_neurips_newton/</guid>
      <description>&lt;p&gt;We just got a notification that our paper (by D. Kovalev, P. Richtárik and me) was accepted to the NeurIPS workshop &amp;ldquo;Beyond First-Order Optimization Methods in Machine Learning&amp;rdquo; for a spotlight (8 minute talk) and poster presentation. Together with the free registration that I got as one of the top reviewers, this gives more than enough reason to attend the conference. We are also waiting for the decisions for our submissions to other workshops, so soon there might be more news!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A new paper which connects Sinkhorn Algorithm and Stochastc Mirror Descent</title>
      <link>https://konstmish.github.io/post/19_sinkhorn/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_sinkhorn/</guid>
      <description>&lt;p&gt;My new paper (for the first time I wrote a single authored work!) is now available online, see the publication section. It turned out the famous Sinkhorn algorithm is nothing but an instance of stochastic mirror descent. Very exciting to see the notion of relative smoothness appear as the only explanation of convergence from the mirror descent perspective.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reviewer for the NeurIPS workshop &#39;Bridging Game Theory and Deep Learning&#39;</title>
      <link>https://konstmish.github.io/post/19_neurips_games_reviewer/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_neurips_games_reviewer/</guid>
      <description>&lt;p&gt;As I&amp;rsquo;ve done some research in the field of minmax optimization and deep learning, I was invited to be a reviewer for this year instance of the Smooth Games Optimization and Machine Learning Series of workshops.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Two new papers on federated learning (and more are coming!)</title>
      <link>https://konstmish.github.io/post/19_fed_learning/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_fed_learning/</guid>
      <description>&lt;p&gt;This summer I collaborated with an intern at our group, Ahmed Khaled (these are just 2 of his 4 first names and he actually doesn&amp;rsquo;t have a last name as any othey Egyptian). The topic of these works is federated learning, which is de facto the standard way of training large models with data from mobile users. Despite its numerical success in certain applications, there are significant difficulties in applying it to setting with heterogeneous data, and in most cases data are not homogeneous. To address why this happens, we tried to tighten the existing theory and found out that our theoretical discoveries have a tight match with numerical experiments. We are still working on this, so more papers are to come!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NeurIPS 2019 Best Reviewer Award</title>
      <link>https://konstmish.github.io/post/19_neurips_award/</link>
      <pubDate>Thu, 05 Sep 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_neurips_award/</guid>
      <description>&lt;p&gt;I received free NeurIPS registration for providing high quality reviews. It is awarded to the top 400 reviewers, and some people call it &amp;ldquo;Best Reviewer Award&amp;rdquo;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AAAI-20: Program Committee member</title>
      <link>https://konstmish.github.io/post/19_aaai/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_aaai/</guid>
      <description>&lt;p&gt;This year I am also serving as a reviewer for the AAAI conference, which will take place in February in New-York. See the official website for more details &lt;a href=&#34;https://aaai.org/Conferences/AAAI-20/#&#34; target=&#34;_blank&#34;&gt;https://aaai.org/Conferences/AAAI-20/#&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My sessions at ICCCOPT</title>
      <link>https://konstmish.github.io/post/19_iccopt/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_iccopt/</guid>
      <description>&lt;p&gt;I was at the ICCOPT conference in Berlin from 5 to 8 August as the chair of 3 sessions: 2 on variational inequality/minimax/GANs and 1 on non-smooth optimization.&lt;/p&gt;

&lt;p&gt;ICCOPT is my favorite conference so far. It was completely devoted to optimization and the density of interesting talks was overwhelming, very often I could not decide to which parallel session I should go. I was lucky to meet with many brilliant people, whose work inspired some of my papers. I find the diversity of the presented topics quite high, and it is surprising how many different ideas and applications are covered by mathematical optimization.&lt;/p&gt;

&lt;p&gt;Organizing was quite fun as well. Next time I may try to organize a couple more sessions to see if it is even more fun at a larger scale.&lt;/p&gt;

&lt;p&gt;My 3 sessions were:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Variational Inequalities, Minimax Problems and GANs (Part 1, Monday). Speakers: Simon Lacoste-Julien, Dmitry Kovalev, Gauthier Gidel.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stochastic Methods for Nonsmooth Optimization (Tuesday). Speakers: Tianyi Lin, Adil Salim and me.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Variational Inequalities, Minimax Problems and GANs (Part 2, Thursday). Speakers: Daoli Zhu,  Sarath Pattathil,  Georgios Piliouras.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More details about the conference can be found here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://iccopt2019.berlin/&#34; target=&#34;_blank&#34;&gt;https://iccopt2019.berlin/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The speakers and the titles of their presentations:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Simon Lacoste-Julien &amp;ldquo;Negative Momentum for Improved Game Dynamics&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dmitry Kovalev &amp;ldquo;Revisiting Stochastic Extragradient Method&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gauthier Gidel &amp;ldquo;New Optimization Perspectives on Generative Adversarial Networks&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Daoli Zhu &amp;ldquo;A Variational Approach on Level sets and Linear Convergence of Variable Bregman Proximal Gradient Method for Nonconvex Optimization Problems&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sarath Pattathil &amp;ldquo;A unified analysis of optimistic gradient and extra-gradient methods for saddle point problems&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Georgios Piliouras &amp;ldquo;Online Optimization in Zero - Sum Games and Beyond: A Dynamical Systems Approach&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tianyi Lin &amp;ldquo;On Gradient Descent Ascent for Nonconvex-Concave Minimax Optimization&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Adil Salim &amp;ldquo;Stochastic Proximal Langevin Algorithm&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Konstantin Mishchenko &amp;ldquo;Variance Reduction for Sums with Smooth and Nonsmooth Components with Linear Convergence&amp;rdquo;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;P.S. Staying in Berlin was as fanstastic as the conference, it is a lovely city and German beer is very helpful for fruitful discussions! :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I am at Simons Institute from 15 to 18 July</title>
      <link>https://konstmish.github.io/post/19_simons/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_simons/</guid>
      <description>&lt;p&gt;I am an attendee of the Frontiers of Deep Learning workshop at Simons Insitute for the Theory of Computing. There many well-known researchers here and just yesterday Yuanzhi Li gave a fantastic talk titled &amp;ldquo;Learning and Generalization in Over-parametrized Neural Networks, Going Beyond Kernels&amp;rdquo;. He presented a very simple explanation of what I believed to be very complicated and I encourage everyone interested in the topic to watch his presentation (should appear on youtube shortly).&lt;/p&gt;

&lt;p&gt;The workshop website is here: &lt;a href=&#34;https://simons.berkeley.edu/programs/dl2019&#34; target=&#34;_blank&#34;&gt;https://simons.berkeley.edu/programs/dl2019&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Update: the talk by Yuanzhi Li is available on Youtube: &lt;a href=&#34;https://www.youtube.com/watch?v=NNPCk2gvTnI&#34; target=&#34;_blank&#34;&gt;https://www.youtube.com/watch?v=NNPCk2gvTnI&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I visited Matthias Ehrhardt at Bath University</title>
      <link>https://konstmish.github.io/post/19_bath/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_bath/</guid>
      <description>&lt;p&gt;Matthias Ehrhardt is a prize fellow at Bath university and I first met him when I visited Cambridge in 2017-2018. Back then I was just a first-year PhD student and it was hard for me to fully understand his work on stochastic primal-dual hybrid gradient (&lt;a href=&#34;https://arxiv.org/abs/1706.04957&#34; target=&#34;_blank&#34;&gt;https://arxiv.org/abs/1706.04957&lt;/a&gt;). However, I have more experience now and just in two weeks I managed to do a nice extension of my recent work (&lt;a href=&#34;https://arxiv.org/abs/1905.11535&#34; target=&#34;_blank&#34;&gt;https://arxiv.org/abs/1905.11535&lt;/a&gt;) to the same setting as in the work by Matthias. The work is motivated by imaging application and I hope it will find important applications in practice.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I was at ICML 2019 presenting the work I did at Amazon</title>
      <link>https://konstmish.github.io/post/19_icml_ts/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_icml_ts/</guid>
      <description>&lt;p&gt;Our work on time series was accepted as a poster to the Time Series Workshop at ICML and I presented it together with Federico Vaggi. The conference was in Los Angeles from 9 to 15 June. I attended it with many other members of our group: Aritra Dutta, Samuel Horvath, Nicolas Loizou, Alibek Sailanbayev, Adil Selim and of course Peter Richtárik.&lt;/p&gt;

&lt;p&gt;You can find the website of the workshop and my paper here: &lt;a href=&#34;http://roseyu.com/time-series-workshop/&#34; target=&#34;_blank&#34;&gt;http://roseyu.com/time-series-workshop/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I am a member of the program committee for NeurIPS and UAI 2019</title>
      <link>https://konstmish.github.io/post/19_neurips_uai/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_neurips_uai/</guid>
      <description>&lt;p&gt;After a successful round of reviews for International Conference on Machine Learning (ICML) I was invited to serve on committee for two more important ML conferences: Conference on Neural Information Processing Systems (NeurIPS) and Uncertainty in Artificial Intelligence (UAI). The review period for UAI is from 21 March to 21 April 2019 and all paper submissions have already been done, while for NeurIPS the deadline to submit a paper is on 23 May 2019 and the review period is from 18 June to 15 July 2019.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;m visiting Martin Jaggi from 18 February to 15 March</title>
      <link>https://konstmish.github.io/post/18_epfl/</link>
      <pubDate>Sun, 17 Feb 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/18_epfl/</guid>
      <description>&lt;p&gt;There is no specific project to work on yet, but my research interests are almost a subset of what Martin and his group have worked on. I would not be surprised if it leads to more than one project and hope that this visit will not be the last one :).&lt;/p&gt;

&lt;p&gt;As of today, the group&amp;rsquo;s website is available at &lt;a href=&#34;https://mlo.epfl.ch/&#34; target=&#34;_blank&#34;&gt;https://mlo.epfl.ch/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our group photo</title>
      <link>https://konstmish.github.io/post/18_group/</link>
      <pubDate>Thu, 07 Feb 2019 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/18_group/</guid>
      <description>





&lt;figure&gt;

&lt;img src=&#34;featured.jpg&#34; &gt;


&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>I am a program committee member for ICML 2019!</title>
      <link>https://konstmish.github.io/post/19_icml/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/19_icml/</guid>
      <description>&lt;p&gt;This is my first time being a reviewer for such a venue, so I hope I will not be &amp;ldquo;that stupid reviewer&amp;rdquo; :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prize winner at IEEEXtreme</title>
      <link>https://konstmish.github.io/post/18_ieeextreme/</link>
      <pubDate>Sun, 21 Oct 2018 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/18_ieeextreme/</guid>
      <description>&lt;p&gt;In a 24 hours programming competition Alibek and I were solving tough mathematical and programming problems for the sake of fun and, &lt;em&gt;maybe&lt;/em&gt;, some prizes. Fortunately, we managed to make it to top 100, which means that we are eligible for prizes from IEEE!&lt;/p&gt;

&lt;p&gt;Last year I participated in the same competition with Samuel Horvath, but back then we were only 123rd.&lt;/p&gt;

&lt;p&gt;Link to the results: &lt;a href=&#34;https://ieeextreme.org/wp-content/uploads/2018/11/IEEEXtreme-12.0-Global-Ranking.pdf&#34; target=&#34;_blank&#34;&gt;https://ieeextreme.org/wp-content/uploads/2018/11/IEEEXtreme-12.0-Global-Ranking.pdf&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A NIPS paper got accepted!</title>
      <link>https://konstmish.github.io/post/18_nips/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/18_nips/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m happy to say that our paper &amp;ldquo;SEGA: Variance Reduction via Gradient Sketching&amp;rdquo; about variance reduction for coordinate descent methods was accepted to NIPS. In this work, we discover how coordinate descent methods can be extended to problems with non-separable regularizer. We consider minibatch, importance sampling and acceleration of the produced method. What&amp;rsquo;s more, we additionally introduced a variant with non-trivial sketches of the gradient, under maximal possible stepsizes can be larger by an arbitrary number than in classical coordinate descent methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;m interning at Amazon August-November</title>
      <link>https://konstmish.github.io/post/18_amazon/</link>
      <pubDate>Thu, 19 Apr 2018 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/18_amazon/</guid>
      <description>&lt;p&gt;During my MSc in Paris, we had an amazing course taught by Fabian Pedregosa (&lt;a href=&#34;http://fa.bianp.net/&#34; target=&#34;_blank&#34;&gt;http://fa.bianp.net/&lt;/a&gt;) and Fajwel Fogel (&lt;a href=&#34;http://www.di.ens.fr/~fogel/&#34; target=&#34;_blank&#34;&gt;http://www.di.ens.fr/~fogel/&lt;/a&gt;). In this course, we learnt how to use Python for data analysis and to evaluate our knowledge we needed to participate in a challenge with other Paris students. Together with Matthieu Mazzolini and Paul Dufosse (they are very cool guys) I chose PlumeLabs challenge where the data was the air pollution in different cities over time. Long story short, we won it, which is totally due to my teammates, I would never be able to do it alone.&lt;/p&gt;

&lt;p&gt;Back then, both Fabian and Fajwel were supervised by Alexandre d&amp;rsquo;Aspremont (postdoc and PhD student respectively). And they invited another postdoc of Alexandre, Federico Vaggi, to help them with grading our final presentations. Based on our grade, I guess that we made good impression on them, and I was pretty happy about it.&lt;/p&gt;

&lt;p&gt;What is interesting is that Federico just a few weeks later was already working at Amazon. Last Fall I wrote Federico an email and after a few interviews a got accepted to intern in the same research team.
The topic of my internship is not specified yet, but it will involve research in machine learning for problems motivated by Amazon&amp;rsquo;s needs. The coolest thing is that while the team&amp;rsquo;s work is very applied, for my internship they agree to work on quite theoretical topics, so that I would be able to use it for my PhD. Let us see what results I will have by the end of my internship.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>After the first hackathon at the Vatican</title>
      <link>https://konstmish.github.io/post/18mar_vatican/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/18mar_vatican/</guid>
      <description>&lt;p&gt;To begin with, the pope didn&amp;rsquo;t come to us to say &amp;ldquo;hi&amp;rdquo;. He gave a speech from a balcony instead and it was the first time he said &amp;ldquo;hackathon&amp;rdquo; in public. Moreover, it would be unfair to say that we were not welcome: the Vatican invested deeply in this event.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://konstmish.github.io/img/vatican_priest.jpg&#34; alt=&#34;priest&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The hackathon went well, although our team didn&amp;rsquo;t win anything. It was a nice experience and since I didn&amp;rsquo;t expect to win a hackathon at the first attempt, I&amp;rsquo;m pretty happy about having being there. And as we actually did work a lot on our project, after coming back to KAUST I had an amazing 12-hours sleep.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://konstmish.github.io/img/major_league_hacking.jpg&#34; alt=&#34;coding&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What was really surprising is the dinner that we had in a private palace. This palace is called &amp;ldquo;Palazzo Taverna&amp;rdquo; and was built by Cardinal Giordano Orsini approximately in 1400. There is a short wikipedia page in Italian about it: &lt;a href=&#34;https://it.wikipedia.org/wiki/Palazzo_Taverna_(Roma)&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;. Every room looks so fancy, there are so many paintings everywhere, it looks overwhelmingly luxurious. I bet everyone was impressed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://konstmish.github.io/img/vatican_paintings.jpg&#34; alt=&#34;vatican_paintings&#34; /&gt;
&lt;img src=&#34;https://konstmish.github.io/img/vatican_dinner.jpg&#34; alt=&#34;vatican_dinner&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VHacks – A hackathon at the Vatican</title>
      <link>https://konstmish.github.io/post/18jan_vatican/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/18jan_vatican/</guid>
      <description>&lt;p&gt;I was selected to be one of 120 students invited to the Vatican to participate in a hackathon. Hackathon&amp;rsquo;s theme are (1) social inclusion, (2) interfaith dialogue and (3) migrants &amp;amp; refugees. I am no expert in religions or migrants problems, so I applied and got accepted to participate addressing the first theme.&lt;/p&gt;

&lt;p&gt;The even is organized by OPTIC - &amp;ldquo;an organization founded in 2012 dedicated to research and innovation regarding the ethics of new and disruptive technologies&amp;rdquo;. More details can be found on this webpage:
&lt;a href=&#34;https://vhacks.org/faq/&#34; target=&#34;_blank&#34;&gt;https://vhacks.org/faq/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t have a good hackathon participations record, but I believe it will be amazing :) It is especially nice to represent KAUST in such an event.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>INFORMS Optimization Society Conference</title>
      <link>https://konstmish.github.io/post/18_informs/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/18_informs/</guid>
      <description>&lt;p&gt;In September Peter suggested me to take part in organizing a few sessions at INFORMS Optimization Society Conference. Since I had no idea of what it means back then, I decided to first try with just one. In addition, I could choose to invite either 3 or 4 speakers, and I decided to go for the former option. It allowed me to choose speakers carefully, but unfortunately I didn&amp;rsquo;t foresee that one of the speakers I invited may not be able to come. So now I am going to be a speaker there as well, which is a common phenomenon, though I rather wanted to listen than to present.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visiting Cambridge</title>
      <link>https://konstmish.github.io/post/17_visiting_cambridge/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/17_visiting_cambridge/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m visiting Dr. Carola-Bibiane Schönlieb&amp;rsquo;s group at Cambridge until 9 January. I will also be here for a few more weeks in February.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>IEEEXtreme</title>
      <link>https://konstmish.github.io/post/17_ieeextreme/</link>
      <pubDate>Sun, 22 Oct 2017 00:00:00 +0300</pubDate>
      
      <guid>https://konstmish.github.io/post/17_ieeextreme/</guid>
      <description>&lt;p&gt;I teamed up with Samuel Horvath to participate in a competition called &amp;ldquo;IEEEXtreme&amp;rdquo; organized by IEEE for students worldwide. We got ranked 123 worldwide or 43 in our Region (Africa, Europe and Middle East). Unfortunately, we didn&amp;rsquo;t get in top 100, so we are not going to get T-shirts as a prize, but the competition was extremely fun and it was cool to work with Samuel in a team.&lt;/p&gt;

&lt;p&gt;Official results are available here:
&lt;a href=&#34;http://ieeextreme.org/files/2017/11/IEEEXtreme-11.0-Rankings-Globally.pdf&#34; target=&#34;_blank&#34;&gt;http://ieeextreme.org/files/2017/11/IEEEXtreme-11.0-Rankings-Globally.pdf&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
