<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Konstantin Mishchenko on Konstantin Mishchenko</title>
    <link>https://konstmish.github.io/</link>
    <description>Recent content in Konstantin Mishchenko on Konstantin Mishchenko</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019 Konstantin Mishchenko</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>I am at Simons Institute until 18 July</title>
      <link>https://konstmish.github.io/post/2019_simons/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/post/2019_simons/</guid>
      <description>&lt;p&gt;I am an attendee of the Frontiers of Deep Learning workshop at Simons Insitute for the Theory of Computing. There many well-known researchers here and just yesterday Yuanzhi Li gave a fantastic talk titled &amp;ldquo;Learning and Generalization in Over-parametrized Neural Networks, Going Beyond Kernels&amp;rdquo;. He presented a very simple explanation of what I believed to be very complicated and I encourage everyone interested in the topic to watch his presentation (should appear on youtube shortly).&lt;/p&gt;

&lt;p&gt;The workshop website is here: &lt;a href=&#34;https://simons.berkeley.edu/programs/dl2019&#34; target=&#34;_blank&#34;&gt;https://simons.berkeley.edu/programs/dl2019&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I visited Matthias Ehrhardt at Bath University</title>
      <link>https://konstmish.github.io/post/2019_bath/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/post/2019_bath/</guid>
      <description>&lt;p&gt;Matthias Ehrhardt is a prize fellow at Bath university and I first met him when I visited Cambridge in 2017-2018. Back then I was just a first-year PhD student and it was hard for me to fully understand his work on stochastic primal-dual hybrid gradient (&lt;a href=&#34;https://arxiv.org/abs/1706.04957&#34; target=&#34;_blank&#34;&gt;https://arxiv.org/abs/1706.04957&lt;/a&gt;). However, I have more experience now and just in two weeks I managed to do a nice extension of my recent work (&lt;a href=&#34;https://arxiv.org/abs/1905.11535&#34; target=&#34;_blank&#34;&gt;https://arxiv.org/abs/1905.11535&lt;/a&gt;) to the same setting as in the work by Matthias. The work is motivated by imaging application and I hope it will find important applications in practice.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I was at ICML 2019 presenting the work I did at Amazon</title>
      <link>https://konstmish.github.io/post/icml-2019_ts/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/post/icml-2019_ts/</guid>
      <description>&lt;p&gt;Our work on time series was accepted as a poster to the Time Series Workshop at ICML and I presented it together with Federico Vaggi. The conference was in Los Angeles from 9 to 15 June. I attended it with many other members of our group: Aritra Dutta, Samuel Horvath, Nicolas Loizou, Alibek Sailanbayev, Adil Selim and of course Peter Richt√°rik.&lt;/p&gt;

&lt;p&gt;You can find the website of the workshop and my work here: &lt;a href=&#34;http://roseyu.com/time-series-workshop/&#34; target=&#34;_blank&#34;&gt;http://roseyu.com/time-series-workshop/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Self-supervised Approach to Hierarchical Forecasting with Applications to Groupwise Synthetic Controls</title>
      <link>https://konstmish.github.io/publication/time_series/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/publication/time_series/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MISO is Making a Comeback With Better Proofs and Rates</title>
      <link>https://konstmish.github.io/publication/miso/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/publication/miso/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DAve-QN: A Distributed Averaged Quasi-Newton Method with Local Superlinear Convergence Rate</title>
      <link>https://konstmish.github.io/publication/dave_qn/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://konstmish.github.io/publication/dave_qn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Stochastic Decoupling Method for Minimizing the Sum of Smooth and Non-Smooth Functions</title>
      <link>https://konstmish.github.io/publication/stoch_decoupling/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/publication/stoch_decoupling/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Revisiting Stochastic Extragradient</title>
      <link>https://konstmish.github.io/publication/extra_vi/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/publication/extra_vi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stochastic Distributed Learning with Gradient Quantization and Variance Reduction</title>
      <link>https://konstmish.github.io/publication/quant_vr/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/publication/quant_vr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>I am a member of the program committee for NeurIPS and UAI 2019</title>
      <link>https://konstmish.github.io/post/19_neurips_uai/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/post/19_neurips_uai/</guid>
      <description>&lt;p&gt;After a successful round of reviews for International Conference on Machine Learning (ICML) I was invited to serve on committee for two more important ML conferences: Conference on Neural Information Processing Systems (NeurIPS) and Uncertainty in Artificial Intelligence (UAI). The review period for UAI is from 21 March to 21 April 2019 and all paper submissions have already been done, while for NeurIPS the deadline to submit a paper is on 23 May 2019 and the review period is from 18 June to 15 July 2019.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;m visiting Martin Jaggi from 18 February to 15 March</title>
      <link>https://konstmish.github.io/post/18_epfl/</link>
      <pubDate>Sun, 17 Feb 2019 00:00:00 -0800</pubDate>
      
      <guid>https://konstmish.github.io/post/18_epfl/</guid>
      <description>&lt;p&gt;There is no specific project to work on yet, but my research interests are almost a subset of what Martin and his group have worked on. I would not be surprised if it leads to more than one project and hope that this visit will not be the last one :).&lt;/p&gt;

&lt;p&gt;As of today, the group&amp;rsquo;s website is available at &lt;a href=&#34;https://mlo.epfl.ch/&#34; target=&#34;_blank&#34;&gt;https://mlo.epfl.ch/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our group photo</title>
      <link>https://konstmish.github.io/post/18_group/</link>
      <pubDate>Thu, 07 Feb 2019 00:00:00 -0800</pubDate>
      
      <guid>https://konstmish.github.io/post/18_group/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;featured.jpg&#34; /&gt;


&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>99% of Distributed Optimization is a Waste of Time: The Issue and How to Fix it</title>
      <link>https://konstmish.github.io/publication/99/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 -0800</pubDate>
      
      <guid>https://konstmish.github.io/publication/99/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Distributed Learning with Compressed Gradient Differences</title>
      <link>https://konstmish.github.io/publication/diana/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 -0800</pubDate>
      
      <guid>https://konstmish.github.io/publication/diana/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Stochastic Penalty Model for Convex and Nonconvex Optimization with Big Constraints</title>
      <link>https://konstmish.github.io/publication/penalty/</link>
      <pubDate>Wed, 31 Oct 2018 00:00:00 -0700</pubDate>
      
      <guid>https://konstmish.github.io/publication/penalty/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
